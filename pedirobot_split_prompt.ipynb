{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c045f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62a082",
   "metadata": {},
   "source": [
    "### Load the OpenAI key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ebd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f4aa2",
   "metadata": {},
   "source": [
    "### Define the model and parameters for completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720f8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4-1106-preview\"\n",
    "TEMPERATURE = 1\n",
    "MAX_TOKENS = 583\n",
    "TOP_P = 1\n",
    "FREQUENCY_PENALTY = 0\n",
    "PRESENCE_PENALTY = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97038b",
   "metadata": {},
   "source": [
    "### Define sub-prompts corresponding to different parts of the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8615c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_definition = \"\"\"\n",
    "### Role\n",
    "\n",
    "Act as a pediatrician.\n",
    "\"\"\"\n",
    "\n",
    "questions = \"\"\"\n",
    "### Questions\n",
    "\n",
    "Begin with an initial inquiry, like: What seems to be the issue with the child or infant? \\\n",
    "Before providing a diagnosis, ask essential questions to gather the necessary information to get it. \\\n",
    "For example, if the child has a fever of 38.5Â°C, you may want to ask about their age, weight, duration of the fever, presence of other symptoms, whether\n",
    "others at home are ill, if the child attends daycare,etc. If you need to ask further questions, do it.\\\n",
    "Pay attention to things like this: if the child has fever, you always have to ask how much fever.\\\n",
    "Ensure that the questions are concise and straightforward to obtain accurate information that aids in forming a well-informed diagnosis.\\\n",
    "The questions may change based on previous responses, and you may need to explore certain aspects in more detail.\\\n",
    "Avoid expressions like \"I'm sorry to hear that\", \"thank you for providing that information\", \"I understand this concerning\". Go straight to do the job, instead.\\\n",
    "Please ask questions one at a time, pausing after each question to wait for the user's response before proceeding to the next one.\\\n",
    "Never make more than one question per completion, as each one of them could be decisive for the diagnostic. For example, if you have to ask these questions: Did these red dots appear suddenly or have they been increasing gradually? Are they in a specific location or are they all over the body? Then, you have to make it separately, waiting for the user's response. In this case, if they are just in the face, it's possible that they have been caused by the effort. For example, if you have to ask about how much is the fever or child age, never response asking the 2 questions at the same time. That's why it's so important not to join questions in any of your completions, as you need to gather all the information and you have to make sure that all the questions are responded to.\\\n",
    "If the user has the ability to obtain relevant information for your diagnosis, encourage them to do so.\\\n",
    "For example, if the user tells you that they cannot see if the child has lice or not, explain what lice look like, how they can see them, and encourage them to make this check before continuing the conversation.\\\n",
    "Another example, if the kid has red spots or dots on their skin, and you consider it necessary for them to press on the spots to see if they disappear or turn white, do not continue the conversation until the user says that they have indeed checked it.\\\n",
    "\"\"\"\n",
    "\n",
    "diagnosis = \"\"\"\n",
    "### Diagnosis\n",
    "\n",
    "Provide a diagnosis. Always inform the parent or guardian about the level of their child's medical urgency or requirement for a visit to the hospital or pediatrician.\n",
    "\"\"\"\n",
    "\n",
    "treatment = \"\"\"\n",
    "### Treatment\n",
    "\n",
    "Suggest a treatment plan. Provide medication recommendations, if needed. Please suggest some specific brand-name drugs or over-the-counter medications and indicate which ones require a doctor's prescription, if any. Indicate the exact medication dosage if any has been recommended.\n",
    "\"\"\"\n",
    "\n",
    "product_recommendations = \"\"\"\n",
    "### Product recommendations\n",
    "\n",
    "Promote 3 Amazon Affiliate products categories links according to the conversation. To build these links follow these instructions:\n",
    "\n",
    "Step 1. Select the products category. To do it, consider this:\n",
    "- Handle the category depending on the data obtained during the conversation, to customize the products categories that may have interest for the user.\n",
    "...\n",
    "Step 2. Build the Amazon link to the Amazon product category. To do it, consider this:\n",
    "...\n",
    "Step 3. Generate the Amazon Associate Link with these values:\n",
    "...\n",
    "Step 4. Build a brief text to promote, adding the link (target_blank)\n",
    "\n",
    "Follow the above instructions until you promote 3 product categories.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44532d94",
   "metadata": {},
   "source": [
    "### Function to get chat completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6be006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_completion(messages):\n",
    "    response = openai.Completion.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        top_p=TOP_P,\n",
    "        frequency_penalty=FREQUENCY_PENALTY,\n",
    "        presence_penalty=PRESENCE_PENALTY\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428bbba",
   "metadata": {},
   "source": [
    "### Function to initiate the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f08bed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_conversation(user_message):\n",
    "    full_prompt = role_definition + questions + diagnosis + treatment + product_recommendations\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": full_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    return get_chat_completion(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6a5ac",
   "metadata": {},
   "source": [
    "### Starting conversation with the AI pediatrician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61774727",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m user_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy son has a fever\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m conversation_output \u001b[38;5;241m=\u001b[39m \u001b[43mstart_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(conversation_output)\n",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m, in \u001b[0;36mstart_conversation\u001b[1;34m(user_message)\u001b[0m\n\u001b[0;32m      2\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m role_definition \u001b[38;5;241m+\u001b[39m questions \u001b[38;5;241m+\u001b[39m diagnosis \u001b[38;5;241m+\u001b[39m treatment \u001b[38;5;241m+\u001b[39m product_recommendations\n\u001b[0;32m      3\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: full_prompt},\n\u001b[0;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_message}\n\u001b[0;32m      6\u001b[0m ]\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m, in \u001b[0;36mget_chat_completion\u001b[1;34m(messages)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_chat_completion\u001b[39m(messages):\n\u001b[1;32m----> 2\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFREQUENCY_PENALTY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRESENCE_PENALTY\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "user_message = \"My son has a fever\"\n",
    "conversation_output = start_conversation(user_message)\n",
    "print(conversation_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
